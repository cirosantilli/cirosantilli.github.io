<!doctype html>
<html lang=en>
<head>
<meta charset=utf-8>
<title>Ollama - Ciro Santilli</title>
<meta property="og:title" content="Ollama - Ciro Santilli">
<meta property="og:type" content="website">
<meta property="og:image" content="https://raw.githubusercontent.com/cirosantilli/media/master/ID_photo_of_Ciro_Santilli_taken_in_2013_square_398.jpg">
<meta property="og:url" content="https://cirosantilli.com/ollama">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.10.1/css/all.min.css" integrity="sha512-9my9Mb2+0YO+I4PUCSwUYO7sEK21Y0STBAiFEYoWtd2VzLEZZ4QARDrZ30hdM1GlioHJ8o8cWQiy8IAb1hy/Hg==" crossorigin="anonymous" referrerpolicy="no-referrer">
<link rel="canonical" href="https://ourbigbook.com/cirosantilli/ollama">
<style>@import "_obb/dist/ourbigbook.css";

</style>
<link rel="stylesheet" type="text/css" href="_raw/main.css">
<link rel="shortcut icon" type="image/x-icon" href="https://raw.githubusercontent.com/cirosantilli/media/master/ID_photo_of_Ciro_Santilli_taken_in_2013_square_398.jpg">
</head>
<body>
<header>
<div class="brand-group">
<a href="." class="brand"><img src="https://raw.githubusercontent.com/cirosantilli/media/master/ID_photo_of_Ciro_Santilli_taken_in_2013_right_eye_200_100.jpg" loading="lazy" alt="ID photo of Ciro Santilli taken in 2013 right eye">Ciro Santilli</a>
<a href="https://ourbigbook.com/cirosantilli"><img src="https://raw.githubusercontent.com/cirosantilli/media/master/ourbigbook-logo-v1.svg" loading="lazy" alt="OurBigBook logo">OurBigBook.com</a>
<a class="font-awesome-container" href="https://stackoverflow.com/users/895245"><i class="fab fa-stack-overflow fa-fw icon"></i></a>
<a class="font-awesome-container" href="https://github.com/cirosantilli"><i class="fab fa-github fa-fw icon"></i></a>
<a class="font-awesome-container" href="https://www.linkedin.com/in/cirosantilli"><i class="fab fa-linkedin fa-fw icon"></i></a>
<a class="font-awesome-container" href="https://www.youtube.com/c/CiroSantilli"><i class="fab fa-youtube fa-fw icon"></i></a>
<a class="font-awesome-container" href="https://twitter.com/cirosantilli"><i class="fab fa-twitter fa-fw icon"></i></a>
<a class="font-awesome-container" href="https://www.zhihu.com/people/cirosantilli/activities"><i class="fab fa-zhihu fa-fw icon"></i></a>
<a class="font-awesome-container" href="https://www.weibo.com/p/1005055601627311"><i class="fab fa-weibo fa-fw icon"></i></a>
<a href="sponsor"><span class="icon">$£</span>&nbsp;Sponsor</a>
<a href="https://github.com/cirosantilli/china-dictatorship"><span class="icon">中国</span>独裁统治&nbsp;China Dictatorship 新疆改造中心、六四事件、法轮功、郝海东、709大抓捕、2015巴拿马文件 邓家贵、低端人口、西藏骚乱</a>
</div>
</header>
<main class="ourbigbook">
<div class="h top" id="ollama"><div class="notnav"><h1><a href="">Ollama</a></h1></div><nav class="h-nav h-nav-toplevel"><div class="nav ancestors"><a  href="#_ancestors">&nbsp;...</a><a href="artificial-intelligence#generative-ai"> Generative AI</a><a href="artificial-intelligence#generative-ai-by-modality"> Generative AI by modality</a><a href="artificial-intelligence#ai-text-generation"> AI text generation</a><a href="artificial-intelligence#text-to-text-model"> Text-to-text model</a><a href="artificial-intelligence#large-language-model"> Large language model</a><a href="artificial-intelligence#open-source-llm"> Open source LLM</a></div><div class="nav"><a href="#_toc" class="toc"></a><a href="https://ourbigbook.com/cirosantilli/ollama"><img src="_obb/logo.svg" class="logo" alt=""> OurBigBook.com</a><span class="tags"> Tags: <a href="cirism#good">Good</a></span><a class="nosplit" href="artificial-intelligence#ollama"></a><span class="metrics"><span class="wcntr"> Words: 486</span><span class="dcnt"> Articles: 9</span></span></div></nav></div><div class="p" id="_539"><a href="https://github.com/jmorganca/ollama">github.com/jmorganca/ollama</a></div><div class="p" id="_540"><a href="artificial-intelligence#ollama">Ollama</a> is a highly automated open source wrapper that makes it very easy to run multiple <a href="artificial-intelligence#open-weight-llm-model">Open weight LLM models</a> either on <a href="computer-hardware#central-processing-unit">CPU</a> or <a href="computer-hardware#graphics-processing-unit">GPU</a>.</div><div class="p" id="_541">Its README alone is of great value, serving as a fantastic list of the most popular <a href="artificial-intelligence#open-weight-llm-model">Open weight LLM models</a> in existence.</div><div class="p" id="_542">Install with:<div class="code" id="_543"><div><pre><code>curl https://ollama.ai/install.sh | sh</code></pre></div></div></div><div class="p" id="_544">The below was tested on Ollama 0.1.14 from December 2013.</div><div class="p" id="_545">Download <a href="artificial-intelligence#llama-2-7b">llama2 7B</a> and open a prompt:<div class="code" id="_546"><div><pre><code>ollama run llama2</code></pre></div></div></div><div class="p" id="_547">On <a href="ciro-santilli-s-hardware#lenovo-thinkpad-p14s-gen4-amd">P14s</a> it runs on <a href="computer-hardware#central-processing-unit">CPU</a> and generates a few tokens per second, which is quite usable for a quick interactive play.</div><div class="p" id="_548">As mentioned at <a href="https://github.com/jmorganca/ollama/blob/0174665d0e7dcdd8c60390ab2dd07155ef84eb3f/docs/faq.md">github.com/jmorganca/ollama/blob/0174665d0e7dcdd8c60390ab2dd07155ef84eb3f/docs/faq.md</a> the downloads to under <code>/usr/share/ollama/.ollama/models/</code> and <a href="software#ncdu">ncdu</a> tells me:<div class="code" id="_549"><div><pre><code>--- /usr/share/ollama ----------------------------------
    3.6 GiB [###########################] /.ollama
    4.0 KiB [                           ]  .bashrc
    4.0 KiB [                           ]  .profile
    4.0 KiB [                           ]  .bash_logout</code></pre></div></div>The file:<div class="code" id="_550"><div><pre><code>/usr/share/ollama/.ollama/models/manifests/hf.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/Q2_K</code></pre></div></div>gives a the exact model name and parameters.</div><div class="p" id="_551">We can also do it non-interactively with:<div class="code" id="_552"><div><pre><code>/bin/time ollama run llama2 'What is quantum field theory?'</code></pre></div></div>which gave me:<div class="code" id="_553"><div><pre><code>0.13user 0.17system 2:06.32elapsed 0%CPU (0avgtext+0avgdata 17280maxresident)k
0inputs+0outputs (0major+2203minor)pagefaults 0swaps</code></pre></div></div>but note that there is a random seed that affects each run by default. <a href="artificial-intelligence#_file/ollama-expect">ollama-expect</a> is an attempt to make the output deterministic.</div><div class="p" id="_554">Some other quick benchmarks from <a href="computer-hardware#amazon-ec2-gpu">Amazon EC2 GPU</a> on a <a href="computer-hardware#g4nd-xlarge">g4nd.xlarge</a> instance which had an <a href="computer-hardware#nvidia-t4">Nvidia Tesla T4</a>:<div class="code" id="_555"><div><pre><code>0.07user 0.05system 0:16.91elapsed 0%CPU (0avgtext+0avgdata 16896maxresident)k
0inputs+0outputs (0major+1960minor)pagefaults 0swaps</code></pre></div></div>and on <a href="computer-hardware#nvidia-a10g">Nvidia A10G</a> in an <a href="computer-hardware#g5-xlarge">g5.xlarge</a> instance:<div class="code" id="_556"><div><pre><code>0.03user 0.05system 0:09.59elapsed 0%CPU (0avgtext+0avgdata 17312maxresident)k
8inputs+0outputs (1major+1934minor)pagefaults 0swaps</code></pre></div></div></div><div class="p" id="_557">So it's not too bad, a small article in 10s.</div><div class="p" id="_558">It tends to babble quite a lot by default, but eventually decides to stop.</div><div class="toc-container" id="_toc"><ul><li class="has-child toplevel"><div class="title-div"><div class="arrow"><div></div></div><span class="not-arrow"><a class="title toc" href="#_toc"> Table of contents</a><input class="search" placeholder="🔍 Search. Shortcut: / (slash)"><span class="hover-metadata"><span class="metrics"><span class="wcntr"> 486</span><span class="dcnt"> 9</span></span></span></span></div><ul><li class="has-child"><div id="_toc/llama-cpp"><div class="arrow"><div></div></div><span class="not-arrow"><a href="artificial-intelligence#llama-cpp">llama.cpp</a><span class="hover-metadata"><a href="#_toc" class="u"> Ollama</a><span class="metrics"><span class="wcntr"> 171</span><span class="dcnt"> 2</span></span></span></span></div><ul><li class="has-child"><div id="_toc/llama-cli"><div class="arrow"><div></div></div><span class="not-arrow"><a href="artificial-intelligence#llama-cli">llama-cli</a><span class="hover-metadata"><a href="#_toc/llama-cpp" class="u"> llama.cpp</a><span class="metrics"><span class="wcntr"> 121</span><span class="dcnt"> 1</span></span></span></span></div><ul><li><div id="_toc/llama-cli-inference-batching"><div class="arrow"><div></div></div><span class="not-arrow"><a href="artificial-intelligence#llama-cli-inference-batching">llama-cli inference batching</a><span class="hover-metadata"><a href="#_toc/llama-cli" class="u"> llama-cli</a><span class="metrics"><span class="wcntr"> 18</span></span></span></span></div></li></ul></li></ul><li class="has-child"><div id="_toc/ollama-howto"><div class="arrow"><div></div></div><span class="not-arrow"><a href="artificial-intelligence#ollama-howto">Ollama HOWTO</a><span class="hover-metadata"><a href="#_toc" class="u"> Ollama</a><span class="metrics"><span class="wcntr"> 24</span><span class="dcnt"> 2</span></span></span></span></div><ul><li><div id="_toc/ollama-output-size"><div class="arrow"><div></div></div><span class="not-arrow"><a href="artificial-intelligence#ollama-output-size">Ollama output size</a><span class="hover-metadata"><a href="#_toc/ollama-howto" class="u"> Ollama HOWTO</a></span></span></div></li><li><div id="_toc/ollama-deterministic-output"><div class="arrow"><div></div></div><span class="not-arrow"><a href="artificial-intelligence#ollama-deterministic-output">Ollama deterministic output</a><span class="hover-metadata"><a href="#_toc/ollama-howto" class="u"> Ollama HOWTO</a><span class="metrics"><span class="wcntr"> 24</span></span></span></span></div></li></ul><li class="has-child"><div id="_toc/ollama-parameter"><div class="arrow"><div></div></div><span class="not-arrow"><a href="artificial-intelligence#ollama-parameter">Ollama parameter</a><span class="hover-metadata"><a href="#_toc" class="u"> Ollama</a><span class="metrics"><span class="wcntr"> 57</span><span class="dcnt"> 2</span></span></span></span></div><ul><li class="has-child"><div id="_toc/ollama-set-parameter-on-cli"><div class="arrow"><div></div></div><span class="not-arrow"><a href="artificial-intelligence#ollama-set-parameter-on-cli">Ollama set parameter on CLI</a><span class="hover-metadata"><a href="#_toc/ollama-parameter" class="u"> Ollama parameter</a><span class="metrics"><span class="wcntr"> 56</span><span class="dcnt"> 1</span></span></span></span></div><ul><li><div id="_toc/_file/ollama-expect"><div class="arrow"><div></div></div><span class="not-arrow"><a href="artificial-intelligence#_file/ollama-expect">ollama-expect</a><span class="hover-metadata"><a href="#_toc/ollama-set-parameter-on-cli" class="u"> Ollama set parameter on CLI</a><span class="metrics"><span class="wcntr"> 50</span></span></span></span></div></li></ul></li></ul></li></ul></li></ul></div><h2 id="_ancestors"><a href="#_ancestors"><span class="fa-solid-900 icon"></span> Ancestors <span class="meta">(14)</span></a></h2><div class="list"><ol><li><a href="artificial-intelligence#open-source-llm">Open source LLM</a></li><li><a href="artificial-intelligence#large-language-model">Large language model</a></li><li><a href="artificial-intelligence#text-to-text-model">Text-to-text model</a></li><li><a href="artificial-intelligence#ai-text-generation">AI text generation</a></li><li><a href="artificial-intelligence#generative-ai-by-modality">Generative AI by modality</a></li><li><a href="artificial-intelligence#generative-ai">Generative AI</a></li><li><a href="artificial-intelligence#ai-by-capability">AI by capability</a></li><li><a href="artificial-intelligence">Artificial intelligence</a></li><li><a href="machine-learning">Machine learning</a></li><li><a href="computer">Computer</a></li><li><a href="technology#information-technology">Information technology</a></li><li><a href="technology#area-of-technology">Area of technology</a></li><li><a href="technology">Technology</a></li><li><a href="."><span title="Home" class="fa-solid-900 icon"></span> Home</a></li></ol></div><h2 id="_incoming-links"><a href="#_incoming-links"><span title="Incoming links" class="fa-solid-900 icon"></span> Incoming links <span class="meta">(4)</span></a></h2><div class="list"><ul><li><a href="computer-hardware#amazon-ec2-gpu">Amazon EC2 GPU</a></li><li><a href="artificial-intelligence#llama-cpp">llama.cpp</a></li><li><a href="artificial-intelligence#mlabonne-meta-llama-3-1-8b-instruct-abliterated-gguf">Mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF </a></li><li><a href="artificial-intelligence#ollama">Ollama</a></li></ul></div>
</main>
<footer>
<div>Powered by <a href="https://docs.ourbigbook.com">OurBigBook</a></div>
<div>License: <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> unless noted</div>
<div><a href="https://github.com/cirosantilli/cirosantilli.github.io/issues">Suggestions and corrections</a></div>
<div><a href="contact">Contact Ciro Santilli</a></div>
<div><a href="_dir">Website source code</a></div>
<div><a href="https://github.com/cirosantilli/cirosantilli.github.io">Website source code on GitHub</a></div>
<div><a href="_file/artificial-intelligence.bigb">Source code for this page: artificial-intelligence.bigb</a></div>
<div><a href="https://github.com/cirosantilli/cirosantilli.github.io/blob/f7dac29d5224c15015eee520ccee15a3adb07b98/artificial-intelligence.bigb">Source code for this page on GitHub</a></div>
<div>Cite with: <a href="https://zenodo.org/badge/latestdoi/16453261">this DOI</a></div>
<div><img src="https://raw.githubusercontent.com/cirosantilli/media/master/ID_photo_of_Ciro_Santilli_taken_in_2013_left_eye_200_100.jpg" loading="lazy" alt="ID photo of Ciro Santilli taken in 2013 right eye"></div>
</footer>
<script>
window.ourbigbook_split_headers = true;
window.ourbigbook_html_x_extension = false;
window.ourbigbook_redirect_prefix = "";
</script>
<script src="_obb/dist/ourbigbook_runtime.js"></script><script>ourbigbook_runtime.ourbigbook_runtime()</script><script src="_raw/main.js"></script>
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-47867706-1', 'auto');
ga('send', 'pageview');
</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-DEE2HEJW9X"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-DEE2HEJW9X');
</script>
<script src="https://giscus.app/client.js"
        data-repo="cirosantilli/cirosantilli.github.io"
        data-repo-id="MDEwOlJlcG9zaXRvcnkxNjQ1MzI2MQ=="
        data-category="giscus"
        data-category-id="DIC_kwDOAPsOjc4CZ6zZ"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="dark_high_contrast"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
</body>
</html>
