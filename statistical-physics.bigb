= Statistical physics
{wiki}

= Statistical mechanics
{parent=Statistical physics}
{wiki}

= Kinetic theory of gases
{parent=Statistical mechanics}
{wiki}

Theory that gases are made up of a bunch of small billiard balls that don't interact with each other.

This theory attempts to deduce/explain properties of matter such as the <equation of state> in terms of <classical mechanics>.

= Statistical mechanics model
{parent=Statistical mechanics}

= Percolation
{parent=Statistical mechanics model}
{wiki}

= Percolation theory
{parent=Percolation}
{wiki}

This field is likely both ugly and useless.

OK, in 2D they've achieved some cute <rational number> results. But still.

= Sedimentation
{parent=Statistical physics}
{wiki}

= Maxwell-Boltzmann vs Bose-Einstein vs Fermi-Dirac statistics
{c}
{parent=Statistical physics}

= Maxwell-Boltzmann vs Bose-Einstein vs Fermi-Diract statisics
{synonym}

<Maxwell-Boltzmann statistics>, <Bose-Einstein statistics> and <Fermi-Dirac statistics> all describe how energy is distributed in different physical systems at a given temperature.

For example, <Maxwell-Boltzmann statistics> describes how the speeds of particles are distributed in an <ideal gas>.

The <temperature> of a gas is only a statistical average of the total <energy> of the gas. But at a given temperature, not all particles have the exact same speed as the average: some are higher and others lower than the average.

For a large number of particles however, the fraction of particles that will have a given speed at a given temperature is highly deterministic, and it is this that the distributions determine.

One of the main interest of learning those statistics is determining the probability, and therefore average speed, at which some event that requires a minimum energy to happen happens. For example, for a <chemical reaction> to happen, both input molecules need a certain speed to overcome the <potential barrier> of the reaction. Therefore, if we know how many particles have energy above some threshold, then we can estimate the speed of the reaction at a given temperature.

The three distributions can be summarized as:
* <Maxwell-Boltzmann statistics>: statistics without considering <quantum> statistics. It is therefore only an approximation. The other two statistics are the more precise quantum versions of <Maxwell-Boltzmann> and tend to it at high <temperatures> or low concentration. Therefore this one works well at high temperatures or low concentrations.
* <Bose-Einstein statistics>: <quantum> version of <Maxwell-Boltzmann statistics> for <bosons>
* <Fermi-Dirac statistics>: <quantum> version of <Maxwell-Boltzmann statistics> for <fermions>. Sample system: electrons in a metal, which creates the <free electron model>. Compared to <Maxwell-Boltzmann statistics>, this explained many important experimental observations such as the <specific heat capacity> of metals. A very cool and concrete example can be seen at https://youtu.be/5V8VCFkAd0A?t=1187 from <video Using a Photomultiplier to Detect Single Photons by Huygens Optics> where spontaneous <field electron emission> would follow <Fermi-Dirac statistics>. In this case, the electrons with enough energy are undesired and a source of <noise> in the experiment.

\Image[https://upload.wikimedia.org/wikipedia/commons/d/d8/Quantum_and_classical_statistics.png]
{title=<Maxwell-Boltzmann> vs Bose-Einstein vs Fermi-Dirac statistics}

A good conceptual starting point is to like the example that is mentioned at <The Harvest of a Century by Siegmund Brandt (2008)>.

Consider a system with 2 particles and 3 states. Remember that:
* in <quantum statistics> (<Bose-Einstein statistics> and <Fermi-Dirac statistics>), particles are indistinguishable, therefore, we might was well call both of them `A`, as opposed to `A` and `B` from non-quantum statistics
* in <Bose-Einstein statistics>, two particles may occupy the same state. In <Fermi-Dirac statistics>

Therefore, all the possible way to put those two particles in three states are for:
* <Maxwell-Boltzmann distribution>: both A and B can go anywhere:
  || State 1
  || State 2
  || State 3

  | AB
  |
  |

  |
  | AB
  |

  |
  |
  | AB

  | A
  | B
  |

  | B
  | A
  |

  | A
  |
  | B

  | B
  |
  | A

  |
  | A
  | B

  |
  | B
  | A
* <Bose-Einstein statistics>: because A and B are indistinguishable, there is now only 1 possibility for the states where A and B would be in different states.
  || State 1
  || State 2
  || State 3

  | AA
  |
  |

  |
  | AA
  |

  |
  |
  | AA

  | A
  | A
  |

  | A
  |
  | A

  |
  | A
  | A
* <Fermi-Dirac statistics>: now states with two particles in the same state are not possible anymore:
  || State 1
  || State 2
  || State 3

  | A
  | A
  |

  | A
  |
  | A

  |
  | A
  | A

= Maxwell-Boltzmann distribution
{c}
{parent=Maxwell-Boltzmann vs Bose-Einstein vs Fermi-Dirac statistics}
{title2=MB distribution}
{wiki=Maxwell–Boltzmann_distribution}

\Image[https://en.wikipedia.org/wiki/File:Maxwell-Boltzmann_distribution_1.png]
{title=Maxwell-Boltzmann distribution for three different <temperatures>}

= Maxwell-Boltzmann statistics
{c}
{parent=Maxwell-Boltzmann distribution}
{wiki}

= Maxwell-Boltzmann
{synonym}

= Experimental verification of the Maxwell-Boltzmann distribution
{parent=Maxwell-Boltzmann distribution}

Most <applications of the Maxwell-Boltzmann distribution> confirm the theory, but don't give a very direct proof of its curve.

Here we will try to gather some that do.

= Zartman Ko experiment
{c}
{parent=Experimental verification of the Maxwell-Boltzmann distribution}
{tag=Physics experiment without a decent modern video}

Measured particle speeds with a rotation barrel! OMG, pre <electromagnetism> equipment?
* https://bingweb.binghamton.edu/~suzuki/GeneralPhysNote_PDF/LN19v7.pdf
* https://chem.libretexts.org/Bookshelves/Physical_and_Theoretical_Chemistry_Textbook_Maps/Book%3A_Thermodynamics_and_Chemical_Equilibrium_(Ellgen)/04%3A_The_Distribution_of_Gas_Velocities/4.07%3A_Experimental_Test_of_the_Maxwell-Boltzmann_Probability_Density

= Stern-Zartman experiment
{c}
{parent=Zartman Ko experiment}
{title2=1920}

Is it the same as <Zartman Ko experiment>? TODO find the relevant papers.
* https://encyclopedia2.thefreedictionary.com/Stern-Zartman+Experiment

= Application of the Maxwell-Boltzmann distribution
{parent=Experimental verification of the Maxwell-Boltzmann distribution}

= Applications of the Maxwell-Boltzmann distribution
{synonym}

https://edisciplinas.usp.br/pluginfile.php/48089/course/section/16461/qsp_chapter7-boltzman.pdf mentions
* <sedimentation>
* <reaction rate> as it calculates how likely it is for particles to overcome the <activation energy>

= Quantum statistics
{parent=Maxwell-Boltzmann vs Bose-Einstein vs Fermi-Dirac statistics}
{wiki=Particle_statistics\#Quantum_statistics}

= Bose-Einstein statistics
{c}
{parent=Quantum statistics}
{title2=BE statistics}
{wiki=Bose–Einstein_statistics}

Start by looking at: <Maxwell-Boltzmann vs Bose-Einstein vs Fermi-Dirac statistics>.

= Fermi-Dirac statistics
{c}
{parent=Quantum statistics}
{title2=FD statistics}
{wiki=Fermi–Dirac_statistics}

= Fermi-Dirac
{synonym}

Start by looking at: <Maxwell-Boltzmann vs Bose-Einstein vs Fermi-Dirac statistics>.

= Quantum statistical mechanics
{parent=Fermi-Dirac statistics}
{wiki}

Bibliography:
* https://stanford.edu/~jeffjar/statmech/lec3.html

= Thermodynamics
{parent=Statistical physics}
{wiki}

= Boltzmann constant
{c}
{parent=Thermodynamics}
{title2=$k_B$, $1.38×10^{-23}$}
{wiki}

This is not a truly "fundamental" constant of nature like say the <speed of light> or the <Planck constant>.

Rather, it is just a definition of our <Kelvin> temperature scale, linking average microscopic energy to our macroscopic temperature scale.

The way to think about that link is, at 1 <Kelvin>, each particle has average energy:
$$
1/2 kT
$$
per degree of freedom.

This is why the units of the Boltzmann constant are <Joules> per <Kelvin>.

For an ideal <monatomic gas>, say <helium>, there are 3 degrees of freedom. so each helium atom has average energy:
$$
3/2 k_B T
$$

If we have 2 atoms at 1 K, they will have average energy $6/2 k_B J$, and so on.

Another conclusion is that this defines <temperature> as being proportional to the total energy. E.g. if we had 1 helium atom at 2 K then we would have about $6/2 k_B J$ energy, 3 K $9/2 k_B J$ and so on.

This energy is of course just an average: some particles have more, and others less, following the <Maxwell-Boltzmann distribution>.

= Equipartition theorem
{parent=Thermodynamics}
{wiki}

= Thermodynamic potential
{parent=Thermodynamics}
{wiki}

https://chemistry.stackexchange.com/questions/7696/how-do-i-distinguish-between-internal-energy-and-enthalpy/7700#7700 has a good insight:
> To summarize, internal energy and enthalpy are used to estimate the thermodynamic potential of the system. There are other such estimates, like the Gibbs free energy G. Which one you choose is determined by the conditions and how easy it is to determine pressure and volume changes.

= Enthalpy
{parent=Thermodynamic potential}
{title2=$H$}
{wiki}

Adds up chemical energy and kinetic energy.

Wikipedia mentions however that the kinetic energy is often negligible, even for gases.

The sum is of interest when thinking about reactions because chemical reactions can change the number of molecules involved, and therefore the pressure.

To predict if a reaction is spontaneous or not, negative enthalpy is not enough, we must also consider <entropy> via <Gibbs free energy>.

Bibliography:
* https://chemistry.stackexchange.com/questions/7696/how-do-i-distinguish-between-internal-energy-and-enthalpy

= Gibbs free energy
{c}
{parent=Thermodynamic potential}
{title2=$G$}
{wiki}

TODO understand more intuitively how that determines if a reaction happens or not.

$$
\Delta G = \Delta H - T \Delta S
$$

At least from the formula we see that:
* the more exothermic, the more likely it is to occur
* if the entropy increases, the higher the temperature, the more likely it is to occur
  * otherwise, the lower the temperature the more likely it is to occur

A prototypical example of reaction that is exothermic but does not happen at any temperature is combustion.

\Video[https://www.youtube.com/watch?v=DKiBA35Nqp4]
{title=Lab 7 - Gibbs Free Energy by MJ Billman (2020)}
{description=Shows the shift of equilibrium due to temperature change with a color change in a HCl CoCl reaction. Unfortunately there are no conclusions because its student's homework.}

= Chemical equilibrium
{c}
{parent=Gibbs free energy}
{wiki}

= Reversible reaction
{c}
{parent=Gibbs free energy}
{wiki}

I think these are the ones where $\Delta H \times \Delta S > 0$, i.e. <enthalpy> and <entropy> push the reaction in different directions. And so we can use temperature to move the <Chemical equilibrium> back and forward.

\Video[https://www.youtube.com/watch?v=NMIoon-kuQ4]
{title=Demonstration of a Reversible Reaction by Rugby School Chemistry (2020)}
{description=Hydrated copper(ii) sulfate.}

= Equation of state
{parent=Thermodynamics}
{wiki}

= Ideal gas law
{parent=Equation of state}
{wiki}

= Ideal gas
{synonym}

= Monatomic gas
{parent=Ideal gas law}
{wiki}

= Entropy
{parent=Thermodynamics}
{wiki}

OK, can someone please just stop the philosophy and give numerical predictions of how entropy helps you predict the future?

The original notion of entropy, and the first one you should study, is the <Clausius entropy>.

For entropy in chemistry see: <entropy of a chemical reaction>.

\Video[https://www.youtube.com/watch?v=0-yhZFDxBh8]
{title=The Unexpected Side of Entropy by Daan Frenkel}
{description=2021.}

\Video[https://www.youtube.com/watch?v=rBPPOI5UIe0]
{title=The Biggest Ideas in the Universe | 20. Entropy and Information by <Sean Carroll> (2020)}
{description=In usual <Sean Carroll> fashion, it glosses over the subject. This one might be worth watching. It mentions 4 possible definitions of entropy: Boltzmann, Gibbs, Shannon (<information theory>) and <John von Neumann> (<quantum mechanics>).}

* https://www.quantamagazine.org/what-is-entropy-a-measure-of-just-how-little-we-really-know-20241213/ What Is Entropy? A Measure of Just How Little We Really Know. on <Quanta Magazine> attempts to make the point that entropy is observer dependant. TODO details on that.

= Clausius entropy
{c}
{parent=Entropy}
{wiki=Entropy_(classical_thermodynamics)}

= Carnot cycle
{c}
{parent=Clausius entropy}
{wiki}

TODO why it is optimal: https://physics.stackexchange.com/questions/149214/why-is-the-carnot-engine-the-most-efficient

= Second law of thermodynamics
{parent=Entropy}
{wiki}

= Second law
{synonym}

<Subtle is the Lord by Abraham Pais (1982)> chapter 4 "Entropy and Probability" mentions well how <Boltzmann> first thought that the second law was an actual base physical law of the universe while he was calculating numerical stuff for it, including as late as 1872.

But then he saw an argument by <Johann Joseph Loschmidt> that given the <time reversibility of classical mechanics>, and because they were thinking of atoms as classical balls as in the <kinetic theory of gases>, then there always exist a valid physical state where entropy decreases, by just reversing the direction of time and all particle speeds.

So from this he understood that the second law can only be probabilistic, and not a fundamental law of physics, which he published clearly in 1877.

= Time reversibility
{parent=Second law of thermodynamics}
{wiki}

= Arrow of time
{parent=Time reversibility}
{wiki}

= Time reversibility of classical mechanics
{parent=Time reversibility}

Considering e.g. <Newton's laws of motion>, you take a system that is a function of time $f(t)$, e.g. the position of many point particles, and then you reverse the speeds of all particles, then $f(-t)$ is a solution to that.

= Time reversibility of gravity
{parent=Time reversibility}

https://physics.stackexchange.com/questions/288339/does-gravity-break-time-reversibility-on-the-microlevel

I guess you also have to change the sign of the <gravitational constant>?

= Phase
{disambiguate=matter}
{parent=Thermodynamics}
{wiki}

= Phase
{synonym}

= List of phase transitions
{parent=Phase (matter)}

= Evaporation
{parent=List of phase transitions}
{wiki}

= Evaporate
{synonym}

= Sublimation
{parent=List of phase transitions}
{wiki=Sublimation_(phase_transition)}

= Sublimate
{synonym}

= Sublimates
{synonym}

= Phase transition
{parent=Phase (matter)}
{wiki}

TODO can anything interesting and deep be said about "why phase transition happens?" https://physics.stackexchange.com/questions/29128/what-causes-a-phase-transition on <Physics Stack Exchange>

= Phase diagram
{parent=Phase transition}
{wiki}

= Type of phase diagram
{parent=Phase diagram}

= Temperature-pressure phase diagram
{parent=Type of phase diagram}

This is the most classical type of phase diagram, widely used when considering a <substance> at a fixed composition.

= Composition phase diagram
{parent=Type of phase diagram}

Composition phase diagrams are <phase diagrams> that also consider variations in composition of a mixture. The most classic of such diagrams are <temperature-composition phase diagrams> for <binary alloys>.

= Temperature-composition phase diagram
{parent=Composition phase diagram}

= Triple point
{parent=Phase diagram}
{wiki}

= Critical point
{disambiguate=thermodynamics}
{parent=Phase diagram}
{wiki}

= Second-order phase transition
{parent=Phase transition}

Mentioned at: https://en.wikipedia.org/wiki/Phase_transition#Modern_classifications

The more familiar transitions we are familiar with like liquid <water> into solid water happen at constant temperature.

However, other types of phase transitions we are less familiar in our daily lives happen across a continuum of such "state variables", notably:
* <superfluidity> and its related manifestation, <superconductivity>
* <ferromagnetism>

= Refrigerator
{parent=Thermodynamics}
{wiki}

\Video[https://www.youtube.com/watch?v=se1XZ8D_fCM]
{title=Refrigerator - How Does It Work? by Curiosity Show}

= Dilution refrigerator
{parent=Refrigerator}
{wiki}

Reaches 2 mKhttps://en.wikipedia.org/wiki/Dilution_refrigerator{ref}. https://youtu.be/upw9nkjawdy?t=487 from <video Building a quantum computer with superconducting qubits by Daniel Sank (2019)> mentions that 15 mK are widely available.

Used for example in some times of <quantum computers>, notably <superconducting quantum computers>. As mentioned at: https://youtu.be/uPw9nkJAwDY?t=487[], in that case we need to go so low to reduce thermal noise.
* <D-Wave Systems>: https://www.dwavesys.com/tutorials/background-reading-series/introduction-d-wave-quantum-hardware#h2-5 (15mK)

\Video[https://www.youtube.com/watch?v=j0s3uqqXZlc]
{title=This Is What A <Helium> <Dilution refrigerator> Is by <Dietterich Labs> (2019)}

= Cryogen-free dilution refrigerator
{parent=Dilution refrigerator}
{wiki=Dilution_refrigerator\#Cryogen-free_dilution_refrigerators}

= Dilution refrigerator manufacturer
{parent=Dilution refrigerator}

= Bluefors
{c}
{parent=Dilution refrigerator manufacturer}

Users:
* https://www.insidequantumtechnology.com/news-archive/ibm-bluefors-partnership-promises-really-cool-quantum-future/

= Temperature
{parent=Thermodynamics}
{wiki}

= Cold
{synonym}

= Hot
{synonym}

For scales from absolute 0 like <Kelvin>, is proportional to the total kinetic energy of the material.

The <Boltzmann constant> tells us how much energy that is, i.e. gives the slope.

= Standard temperature and pressure
{parent=Temperature}
{wiki}

= Scale of temperature
{parent=Temperature}
{wiki}

= Kelvin
{c}
{parent=Scale of temperature}
{title2=K}
{wiki}

= Thermometer
{parent=Temperature}
{wiki}

= Mercury-in-glass thermometer
{parent=Thermometer}
{wiki}

= Mercury thermometer
{synonym}

= Vacuum
{parent=Thermodynamics}
{wiki}

= Vacuum engineering
{parent=Vacuum}
{wiki}

\Video[https://www.youtube.com/watch?v=VD69crOFx10]
{title=Air-tight vs. Vacuum-tight by <AlphaPhoenix> (2020)}
{description=Shows how to debug a leak in an <ultra-high vacuum> system. Like every other area of engineering, you basically bisect the machine! :-) By https://www.materials.ucsb.edu/people/graduate-student/brian-haidet[Brian Haidet], a PhD at <University of California, Santa Barbara>.}

= Vacuum vendor
{parent=Vacuum engineering}
{wiki}

= Edwards Vacuum
{c}
{parent=Vacuum vendor}
{title2=1919}
{wiki}

= Ultra-high vacuum
{parent=Vacuum engineering}
{title2=UVH, 100 nPA}
{wiki}
